{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83764c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='I am sorry, I cannot fulfill this request. The available tools lack the functionality to query the current time in a specific location.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--21da0e05-7a3d-42bc-9b3a-7994c6547e10-0', usage_metadata={'input_tokens': 54, 'output_tokens': 27, 'total_tokens': 81, 'input_token_details': {'cache_read': 0}})]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Install necessary libraries\n",
    "# pip install -qU langgraph langchain_google_genai duckduckgo-search\n",
    "\n",
    "import os\n",
    "from typing import TypedDict, Annotated, List\n",
    "\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# --- Set up your Gemini API Key ---\n",
    "# Make sure to set your Google API Key in your environment variables\n",
    "# For example, in a Jupyter notebook you can run:\n",
    "# from google.colab import userdata\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
    "\n",
    "os.environ[\"GEMINI_API_KEY\"] = \"AIzaSyAV5oE89q9IBQJGVAiYtLQv2SAaUZVuObs\"\n",
    "\n",
    "## 2. Define the State\n",
    "# The state is the memory of our chatbot. It's a dictionary that must contain\n",
    "# a list of messages. The `Annotated` type hint adds new messages to the\n",
    "# existing list instead of replacing it.\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        messages: The list of messages exchanged in the conversation.\n",
    "    \"\"\"\n",
    "    messages: Annotated[List[BaseMessage], lambda x, y: x + y]\n",
    "\n",
    "\n",
    "## 3. Define the Tools & Model\n",
    "# We'll use DuckDuckGo for web search. Then, we instantiate our Gemini model\n",
    "# and bind the tool to it so the LLM knows it has access to this tool.\n",
    "\n",
    "tool = DuckDuckGoSearchRun()\n",
    "tools = [tool]\n",
    "\n",
    "# We use a pre-built ToolNode to easily handle tool execution.\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Use a Gemini model that supports tool calling, like gemini-1.5-flash.\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
    "\n",
    "# Bind the tools to the model.\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "\n",
    "## 4. Define the Nodes\n",
    "# Nodes are the \"workers\" in the graph. They are functions that perform actions.\n",
    "\n",
    "# This node calls the LLM.\n",
    "def call_model(state):\n",
    "    \"\"\"Invokes the model with the current conversation state.\"\"\"\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    # The response is added to the list of messages.\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "## 5. Define the Conditional Edge\n",
    "# This function decides the next step based on the current state.\n",
    "\n",
    "def should_continue(state):\n",
    "    \"\"\"Determines whether to continue the graph or end.\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    # If the LLM made a tool call, we route to the 'tools' node.\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    # Otherwise, we end the conversation turn.\n",
    "    return END\n",
    "\n",
    "\n",
    "## 6. Build the Graph\n",
    "# We now wire together the state, nodes, and edges to create the flow.\n",
    "\n",
    "# Initialize the graph with our state definition.\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Add the nodes to the graph.\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Set the entry point for the graph.\n",
    "workflow.set_entry_point(\"agent\")\n",
    "\n",
    "# Add the conditional edge. This decides the path after the 'agent' node runs.\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"tools\": \"tools\",  # If the function returns \"tools\", go to the 'tools' node.\n",
    "        END: END           # If it returns END, the graph finishes.\n",
    "    },\n",
    ")\n",
    "\n",
    "# Add a normal edge to create a loop. After the tools are called,\n",
    "# the flow goes back to the agent to process the tool results.\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph into a runnable application.\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "## 7. Run the Chatbot\n",
    "# Now we can invoke the app with a user message and stream the results.\n",
    "\n",
    "inputs = {\"messages\": [HumanMessage(content=\"What is the current time in Visakhapatnam, India?\")]}\n",
    "for output in app.stream(inputs):\n",
    "    # The stream method yields the output from each node as it runs.\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "807b357d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'find_timezone_for_city', 'arguments': '{\"city_name\": \"Visakhapatnam\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--d75d1ba0-c8ea-4966-a4a4-bf8bf00974cc-0', tool_calls=[{'name': 'find_timezone_for_city', 'args': {'city_name': 'Visakhapatnam'}, 'id': '7c90a108-e1ed-4d6d-9a7d-0e274e87e378', 'type': 'tool_call'}], usage_metadata={'input_tokens': 62, 'output_tokens': 14, 'total_tokens': 76, 'input_token_details': {'cache_read': 0}})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tools':\n",
      "---\n",
      "{'messages': [ToolMessage(content='Asia/Kolkata', name='find_timezone_for_city', tool_call_id='7c90a108-e1ed-4d6d-9a7d-0e274e87e378')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_time', 'arguments': '{\"timezone\": \"Asia/Kolkata\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--0e20833b-fa35-4ae1-93a7-8c20c4db0c84-0', tool_calls=[{'name': 'get_current_time', 'args': {'timezone': 'Asia/Kolkata'}, 'id': '747f95bd-7c05-41fb-8b1d-898f6d819830', 'type': 'tool_call'}], usage_metadata={'input_tokens': 87, 'output_tokens': 9, 'total_tokens': 96, 'input_token_details': {'cache_read': 0}})]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'tools':\n",
      "---\n",
      "{'messages': [ToolMessage(content='The current time in Asia/Kolkata is 2025-07-26 21:13:08 IST.', name='get_current_time', tool_call_id='747f95bd-7c05-41fb-8b1d-898f6d819830')]}\n",
      "\n",
      "---\n",
      "\n",
      "Output from node 'agent':\n",
      "---\n",
      "{'messages': [AIMessage(content='The current time in Visakhapatnam, India is 2025-07-26 21:13:08 IST.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-1.5-flash', 'safety_ratings': []}, id='run--a09779f4-2f41-4d1e-8ea9-b0cfaa5aa29b-0', usage_metadata={'input_tokens': 132, 'output_tokens': 34, 'total_tokens': 166, 'input_token_details': {'cache_read': 0}})]}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Install necessary libraries\n",
    "# !pip install -qU langgraph langchain_google_genai pytz\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import pytz  # Library for handling timezones\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.tools import tool # We import the 'tool' decorator\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "# --- Set up your Gemini API Key ---\n",
    "# Make sure your .env file or environment variable is set correctly\n",
    "gemini_api_key = os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "\n",
    "## 2. Define the State (This remains the same)\n",
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], lambda x, y: x + y]\n",
    "\n",
    "\n",
    "## 3. Define the Tools & Model\n",
    "\n",
    "# -- TOOL #1: The missing tool to find the timezone --\n",
    "@tool\n",
    "def find_timezone_for_city(city_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Finds the IANA timezone identifier for a given city name.\n",
    "    \"\"\"\n",
    "    # A simple dictionary to map cities to timezones.\n",
    "    city_map = {\n",
    "        \"visakhapatnam\": \"Asia/Kolkata\",\n",
    "        \"new york\": \"America/New_York\",\n",
    "        \"london\": \"Europe/London\",\n",
    "        \"tokyo\": \"Asia/Tokyo\"\n",
    "    }\n",
    "    return city_map.get(city_name.lower(), f\"Error: Could not find a timezone for the city {city_name}.\")\n",
    "\n",
    "# -- TOOL #2: The tool to get the time --\n",
    "@tool\n",
    "def get_current_time(timezone: str) -> str:\n",
    "    \"\"\"\n",
    "    Returns the current time for a given IANA timezone identifier.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tz = pytz.timezone(timezone)\n",
    "        current_time = datetime.now(tz)\n",
    "        return f\"The current time in {timezone} is {current_time.strftime('%Y-%m-%d %H:%M:%S %Z')}.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: Could not find timezone {timezone}.\"\n",
    "\n",
    "# We give the agent BOTH tools to enable multi-step reasoning.\n",
    "tools = [find_timezone_for_city, get_current_time]\n",
    "tool_node = ToolNode(tools)\n",
    "\n",
    "# Instantiate the model and bind the tools\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0, google_api_key=gemini_api_key)\n",
    "model_with_tools = model.bind_tools(tools)\n",
    "\n",
    "\n",
    "## 4, 5, 6: The graph definition remains the same.\n",
    "def call_model(state):\n",
    "    messages = state[\"messages\"]\n",
    "    response = model_with_tools.invoke(messages)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def should_continue(state):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "    return END\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"agent\", call_model)\n",
    "workflow.add_node(\"tools\", tool_node)\n",
    "workflow.set_entry_point(\"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"agent\",\n",
    "    should_continue,\n",
    "    { \"tools\": \"tools\", END: END }\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "app = workflow.compile()\n",
    "\n",
    "\n",
    "## 7. Run the Chatbot\n",
    "inputs = {\"messages\": [HumanMessage(content=\"what is the current time in Visakhapatnam, India?\")]}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ccbf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticLanggraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
